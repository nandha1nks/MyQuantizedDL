

## Tasks to Complete
- [X] Create basic quantize functions for Int8
  - [X] Symentric vs Asymentric
  - [X] Per tensor, per channel, 
  - [ ] per group
  - [ ] Weight Packing vs Unpacking for INT2 and INT4
- [ ] Create W8A16 Linear Layers
- [ ] Quantize Activations as well
- [ ] Post training Static and Dynamic Quantization
- [ ] Quantization aware training
- [ ] Read about float16 and bfloat16
- [ ] Read about SOTA
